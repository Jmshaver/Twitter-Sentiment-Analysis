{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding=\"ISO-8859-1\",names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "\n",
    "pos100 = df[:1_000]\n",
    "neg100 = df[df[\"target\"] == 4][:1_000]\n",
    "smaller_data = pd.concat([pos100,neg100])\n",
    "smaller_data.reset_index(inplace=True)\n",
    "smaller_data = smaller_data.drop([\"ids\",\"date\", \"flag\", \"user\", \"index\"], axis=1)\n",
    "del(df)\n",
    "smaller_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_handles (text):\n",
    "  return re.sub(\"@[^\\s]+\", \"\", text)\n",
    "\n",
    "def remove_link(text):\n",
    "  return re.sub(r'http\\S+', '', text)\n",
    "  \n",
    "def lower_case(text):\n",
    "  return text.lower()\n",
    "\n",
    "def remove_chars(text):\n",
    "  text  = \"\".join([char for char in text if char not in string.punctuation]) #do we want to replace with space?\n",
    "  text = re.sub('[0-9]+', '', text)\n",
    "  return text\n",
    "\n",
    "def tokenize(text): \n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "def remove_stop_words(words): #works on tokenized data\n",
    "  stopword = nltk.corpus.stopwords.words('english')\n",
    "  stopword.append(\"\")\n",
    "  return [word for word in words if word not in stopword]\n",
    "\n",
    "def stemming(text):\n",
    "  ps = nltk.SnowballStemmer('english')\n",
    "  text = [ps.stem(word) for word in text]\n",
    "  return text\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "  text = remove_handles(text)\n",
    "  text = remove_link(text)\n",
    "  text = lower_case(text)\n",
    "  text = remove_chars(text)\n",
    "  text = tokenize(text)\n",
    "  text = remove_stop_words(text)\n",
    "  text = stemming(text)\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_data[\"cleaned\"] = smaller_data[\"text\"].apply(clean_and_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [awww, that, bummer, shoulda, got, david, carr...\n",
       "1    [upset, cant, updat, facebook, text, might, cr...\n",
       "2    [dive, mani, time, ball, manag, save, rest, go...\n",
       "3               [whole, bodi, feel, itchi, like, fire]\n",
       "4                          [behav, im, mad, cant, see]\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_data[\"cleaned\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_dictionary (df):\n",
    "  dictionary = {}\n",
    "  i = 0\n",
    "  for row in df[\"cleaned\"]:\n",
    "    for word in row:\n",
    "      if word not in dictionary.keys():\n",
    "        dictionary[word] = i\n",
    "        i += 1\n",
    "  return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4052"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = generate_dictionary(smaller_data)\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(df, dictionary):\n",
    "  X=np.zeros((len(df), len(dictionary)))\n",
    "  for index, row in enumerate(df[\"cleaned\"]):\n",
    "    for word in row:\n",
    "      if word in dictionary.keys():\n",
    "        col = dictionary[word]\n",
    "        X[index, col] = 1\n",
    "  return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4052)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = create_feature_matrix(smaller_data, dictionary)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6729999999999999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=2, shuffle=True)\n",
    "# create model\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000 )\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, smaller_data[\"target\"], scoring='accuracy', cv=cv)\n",
    "sum(scores) / len(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22060db212986357581e62361c3eebebeb6449cac1057860b607030f5c42b833"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
